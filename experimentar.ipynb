{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec4e26bc-7629-4c65-b8ba-629738dc9a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aabe91c3fb1468d91d1ff914bd183ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:2137: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Answer: \n",
      "    A user has asked a question, and we have the SQL query used to retrieve data and the result of that query. \n",
      "    Your task is to generate a **clear and friendly answer in natural language**, using the information from the query result. \n",
      "\n",
      "    The question asked by the user is: How many employees are there?\n",
      "    The SQL query used to retrieve the information was: SELECT COUNT(*) FROM employees;\n",
      "    The result of the query is: count: 8\n",
      "\n",
      "    Please provide a **natural language response** to the user's question based on the result of the query. \n",
      "    Do not repeat the SQL query.\n",
      "    \n",
      "    The response should be in the form of a **complete sentence** that answers the user's question. \n",
      "    It should be **clear and easy to understand**, using simple language and avoiding technical jargon. \n",
      "    The response should be **concise**\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "# Carregar o modelo para gerar respostas amigáveis\n",
    "model_name = \"mistralai/Mistral-7B-v0.1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name, torch_dtype=torch.float16, device_map=\"auto\"\n",
    ")\n",
    "def generate_answer(question, query, result):\n",
    "    # Formatando o resultado da consulta para uma string simples\n",
    "    # Supondo que 'result' seja uma lista de dicionários com os dados retornados\n",
    "    result_str = ', '.join([f\"{key}: {value}\" for entry in result for key, value in entry.items()])\n",
    "    \n",
    "    # Definir o prompt para gerar a resposta\n",
    "    prompt = f\"\"\"\n",
    "    A user has asked a question, and we have the SQL query used to retrieve data and the result of that query. \n",
    "    Your task is to generate a **clear and friendly answer in natural language**, using the information from the query result. \n",
    "\n",
    "    The question asked by the user is: {question}\n",
    "    The SQL query used to retrieve the information was: {query}\n",
    "    The result of the query is: {result_str}\n",
    "\n",
    "    Please provide a **natural language response** to the user's question based on the result of the query. \n",
    "    Do not repeat the SQL query.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Tokenizar a entrada\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "    \n",
    "    # Gerar a saída\n",
    "    outputs = model.generate(**inputs, max_length=200)\n",
    "    \n",
    "    # Decodificar e retornar a resposta gerada\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Exemplo de entrada e resultado\n",
    "question = \"How many employees are there?\"\n",
    "query = \"SELECT COUNT(*) FROM employees;\"\n",
    "result = [{\"count\": 8}]  # Exemplo de resultado de consulta SQL\n",
    "\n",
    "answer = generate_answer(question, query, result)\n",
    "print(\"Final Answer:\", answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec82cc88-dc9f-4398-aa70-12838961ad22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ticket']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76df2c02-6fbd-4eb4-abcf-66c6ec658243",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
